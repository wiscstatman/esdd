} else if(result$`Pr(>Chi)`[2] < 0.05){
reject = reject + 1
}
step = step + 1
}
print("N=",N)
print("N="N)
print("N=")
N = 600 #items in each experiment group
K = 6 #treatments and control
T = 4 #time points
dat <- data.frame("time" = c(rep(1,N*K),rep(2,N*K),rep(3,N*K),rep(4,N*K)),
"trt" = rep(c(rep(0,N),rep(1,N),rep(2,N),
rep(3,N),rep(4,N),rep(5,N)),T),
"y" = c(rep(0,2*N*K),rep(1,2*N*K)))
control_rate = c(0.02,0.07,0.2,0.3) #control group rates w./ time
min_diff = 0.2 #minimum difference between control and trt rate
max_diff = 0.3 #maximum difference between control and trt rate
iter = 1000
reject = 0
step = 1
while (step < iter) {
p = matrix(0,T,K) #4 time points, 1 control group and 5 trt group
p[,1] = control_rate # control group success rate on time point 1~4
# p[1,] = rep(control_rate[1],K)
# p[2,] = rep(control_rate[2],K)
for (t in 1:T) {
#p[t,2:K] = runif(K-1,min=0,max=1)
p[t,2:K] = runif(K-1,min = p[t,1] * (1 - max_diff), max = p[t,1] * (1 - min_diff))
}
for (t in 1:T) {
for (k in 1:K) {
begin = N * K * (t - 1) + N * (k - 1) + 1
end = N * K * (t - 1) + N * k
dat$y[begin:end] = rbinom(N,1,p[t,k])
}
}
dat$trt = as.factor(dat$trt)
dat$time = as.factor(dat$time)
dat$y = as.factor(dat$y)
# for (k in 1:(K-1)) {
#   fit1 <- glm(y~time, data = dat[which(dat$trt %in% c(0,k)),],family = "binomial")
#   fit2 <- glm(y~time * trt,data = dat[which(dat$trt %in% c(0,k)),],
#               family = "binomial")
#   result = anova(fit1, fit2, test="LRT")
#   if(is.na(result$`Pr(>Chi)`[2])){
#     next
#   } else if(result$`Pr(>Chi)`[2] < 0.011){
#     reject = reject + 1
#     break
#   }
# }
fit1 <- glm(y~time, data = dat,family = "binomial")
fit2 <- glm(y~time * trt,data = dat, family = "binomial")
result = anova(fit1, fit2, test="LRT")
if(is.na(result$`Pr(>Chi)`[2])){
next
} else if(result$`Pr(>Chi)`[2] < 0.05){
reject = reject + 1
}
step = step + 1
}
power = reject / iter
rm(list = ls())
install.packages("PharmacoGx")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("PharmacoGx")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("PharmacoGx")
install.packages("hexbin")
install.packages("hexbin")
install.packages("hexbin")
install.packages("hexbin")
install.packages("hexbin")
install.packages("hexbin")
install.packages("hexbin")
install.packages(c("pROC", "R.utils"))
install.packages("Rcpp")
library(Rcpp)
library(R.utils)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("PharmacoGx")
install.packages("hexbin")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("PharmacoGx")
library(PharmacoGx)
library(informRset)
data(pkis1)
pkis1 <- t(apply(pkis1, 1, function(x){
thres = mean(x) + 2 * sd(x)
return(as.numeric(x>thres))
}))
mean(pkis1)
detach("package:informRset", unload = TRUE)
load("/Users/pengyu/Upload/CR_Beta_Prior/cl_GDSC.RData")
testresult_nef = read.csv("~/Drug_Discovery/BOISE/CR_BetaPrior/GDSC8_eval_NEF10.csv")
testresult_roc = read.csv("~/Drug_Discovery/BOISE/CR_BetaPrior/GDSC8_eval_ROCAUC.csv")
summary(testresult_nef$AC_BOISE8)
summary(testresult_nef$AS8)
summary(testresult_nef$BOISE5)
t.test(testresult_nef$AC_BOISE8,testresult_nef$AS8,paired = T)
t.test(testresult_roc$AC_BOISE8,testresult_roc$AS8,paired = T)
testresult_nef = read.csv("~/Drug_Discovery/BOISE/CR_BetaPrior/GDSC16_eval_NEF10.csv")
testresult_roc = read.csv("~/Drug_Discovery/BOISE/CR_BetaPrior/GDSC16_eval_ROCAUC.csv")
testresult_roc = read.csv("~/Drug_Discovery/BOISE/CR_BetaPrior/GDSC16_eval_ROC.csv")
t.test(testresult_nef$AC_BOISE16,testresult_nef$AS16,paired = T)
t.test(testresult_roc$AC_BOISE16,testresult_roc$AS16,paired = T)
?pbeta
pbeta(0.5,57.1,43.9,lower.tail = F)
pbeta(0.5,60.2,71.8,lower.tail = F)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/UW/Slides/741/Hw/")
rm(list=ls())
dat = read.csv("PatientInfo.csv")
### Our interested variables,
features = c("patient_id","sex","age", "country","province",
"disease","confirmed_date",
"released_date", "deceased_date", "state")
dat = dat[features]
### Impute unknown response with NA, originally was ""
dat = as.data.frame(apply(dat,2,function(x){
l = length(which(x==""))
x[which(x=="")] = rep(NA,l)
return(x)
}))
summary(dat)
missing = c()
for (i in 1:nrow(dat)) {
if(is.na(dat$confirmed_date[i]) || is.na(dat$state[i])
|| is.na(dat$age[i]) || is.na(dat$sex[i]))
missing = c(missing,i)
}
dat = dat[-missing, ]
dim(dat)
dat$status = 1*(dat$state == "deceased")
dat$time = sapply(1:nrow(dat),function(i){
if(dat$state[i] == "deceased")
return(as.numeric(as.Date(dat$deceased_date[i]) -
as.Date(dat$confirmed_date[i])))
else if(dat$state[i] == "released")
return(as.numeric(as.Date(dat$released_date[i]) -
as.Date(dat$confirmed_date[i])))
else
return(as.numeric(as.Date("2020-03-20") -
as.Date(dat$confirmed_date[i])))
})
sum(is.na(dat$time))
dat = dat[-which(is.na(dat$time)), -c(7:10)]
dat = as.data.frame(apply(dat,2,function(x){
l = length(which(is.na(x)))
x[which(is.na(x))] = rep("unknown",l)
return(x)
}))
dat$time = as.numeric(dat$time)
dat$status = as.numeric(dat$status)-1
summary(dat)
summary(dat$time)
library(dod)
data("precooked")
View(precooked)
theta = precooked$fitJ$thetasave
View(theta)
hist(theta[,1])
hist(theta[,2])
16500*(1+0.056)+400
16900*(1+0.056)+400
1185+21.67
32607+2175
34782-187000
34782-18700
92.4*(1.055)
93.71/92.4
(5.49+6.49)/92.4*93.71
(5.49+9.99+10.99+13.89+6.49+34.57)/92.4*93.71
(5.49+9.99+10.99+13.89+6.49+34.57)
2.99+6.99+8.59+13.99+6.99+12.99
16600*0.056
16600*0.17
800/1.17
5.6+1.1+2.1+2.6+20.07+18.48
?pmultinom
?rmultinom
10!
factor(10)
factorial(10)
dmultinom(c(2,2,1,5), prob = c(0.25,0.25,0.25,0.25))
factorial(10) / factorial(5) / 4 * (0.25)^10
dmultinom(c(2,2,1,5), prob = c(0.3,0.2,0.2,0.3))
dmultinom(c(2,2,1,5), prob = c(0.4,0.1,0.1,0.4))
dmultinom(c(3,1,1,4), prob = c(0.4,0.1,0.1,0.4))
dmultinom(c(2,2,1,5), prob = c(0.4,0.1,0.1,0.4))
0.4^7*0.1^3
0.3^7*0.2^3
p1 = dmultinom(c(2,2,1,5), prob = c(0.25,0.25,0.25,0.25))
p2 = dmultinom(c(2,2,1,5), prob = c(0.3,0.2,0.2,0.3))
p3 = dmultinom(c(2,2,1,5), prob = c(0.4,0.1,0.1,0.4))
p1*0.7 + p2 * 0.2 + p3 * 0.1
(p3 * 0.1 ) / (p1*0.7 + p2 * 0.2 + p3 * 0.1)
(p2 * 0.2 ) / (p1*0.7 + p2 * 0.2 + p3 * 0.1)
test = matrix(c(1,2,3,9,10,3,4,5,6,11,19,27), nrow = 3, ncol = 4)
test = t(test)
svd(test)
X = t(test) %*% test
eigne(X)
eigen(X)
eig = eigen(X)
v1 = eig$vectors[,1]
X %*% v1
eig$values[1] * v1
?rnorm
50*(1.5+1.5^2 + 1.5^3 + 1.5^4+1.5^5)
120*(1.25 + 1.25^2 + 1.25^3 + 1.25^4 + 1.25^5)
setwd("~/RAwork/esdd/BOISE/")
setwd("~/RAwork/esdd/BOISE/Code")
source("Initial_beta.R")
source("Update_beta.R")
source("dpmm_beta.R")
source("clust_sum.R")
source("npel1_beta.R")
source("npel2.R")
source("Boise.R")
source("Boise_Aug.R")
source("Evaluate.R")
#load data
load("pkis1.rda")
## Use 2sd criteria to create binary matrix
dat <- t(apply(pkis1, 1, function(x){
thres = mean(x) + 2 * sd(x)
return(as.numeric(x>thres))
}))
rm(pkis1)
#choose iterations, warm up step, step length
warm = 500
iter = 10
step = 10
#find an empirical best prior mass alpha
alpha = 15
# One experiment in leave-one-out cross validation for BOISE framework
# First create cl_sample objects for ith training set
i = 1
test = dat[i, ]
train = dat[-i, ]
a = rep(mean(train),ncol(train))
b = 1 - a
cl_sample = dpmm_beta(a,b,x0 = train, warm, iter, step, alpha)
nA = 2
nT = 36
size = 1000
inform = Boise(cl_sample, iter,size, nA = nA, nT = nT,a,b, x0 = train,alpha)
Boise <- function(cl_sample, iter, size, nA, nT, a, b, x0, alpha){
#source("clust_sum.R")
#source("npel1.R")
if (!require('parallel')) {
stop('The package parallel was not installed')
}
P = clust_sum(cl_sample,x0,iter, a, b)
n = nrow(x0)
m = ncol(x0)
cl = cl_sample
cl$XX = rep(0, iter*size*m)
dim(cl$XX) = c(iter, size, m)
## Sample for x_i* with sample size "size"
for (j in 1:iter) {
K = cl$KK[j]
p = rep(0, K + 1)
p[K + 1] = alpha / (n + alpha)
p[1:K] = P[[j]][,m+1] / (n+alpha)
cl$XX[j, , ] = t(as.matrix(sapply(1:size, function(s){
classi = which(rmultinom(1, 1, p) == 1)
if(classi == K+1){
post_theta = a / (a + b)
} else{
post_theta = P[[j]][classi,1:m]
}
new_xi = sapply(1:m, function(x){
return(as.numeric(rbinom(1, 1, p = post_theta[x])))
})
return(new_xi)
})))
}
## BOISE selection based on pel1
step = 1
pel1 = unlist(mclapply(1:dim(x0)[2], function(x){
return(pel1_beta(cl, P, iter, size, A = x, nA = step, nT,a,b,x0, alpha))},
mc.cores = detectCores()))
print("ah")
tmp = order(pel1)[1]
inform = tmp
candidate = order(pel1)
while (step < nA) {
step = step +1
candidate = candidate[-which(candidate == tmp)]
pel = rep(0,length(candidate))
pel = unlist(mclapply(candidate, function(x){
return(pel1_beta(cl, P, iter, size, A = c(inform,x), nA = step,nT,a,b,x0, alpha))},
mc.cores = detectCores()))
tmp = candidate[order(pel)[1]]
inform = c(inform, tmp)
}
return(inform)
}
inform = Boise(cl_sample, iter,size, nA = nA, nT = nT,a,b, x0 = train,alpha)
Boise <- function(cl_sample, iter, size, nA, nT, a, b, x0, alpha){
#source("clust_sum.R")
#source("npel1.R")
if (!require('parallel')) {
stop('The package parallel was not installed')
}
P = clust_sum(cl_sample,x0,iter, a, b)
n = nrow(x0)
m = ncol(x0)
cl = cl_sample
cl$XX = rep(0, iter*size*m)
dim(cl$XX) = c(iter, size, m)
## Sample for x_i* with sample size "size"
for (j in 1:iter) {
K = cl$KK[j]
p = rep(0, K + 1)
p[K + 1] = alpha / (n + alpha)
p[1:K] = P[[j]][,m+1] / (n+alpha)
cl$XX[j, , ] = t(as.matrix(sapply(1:size, function(s){
classi = which(rmultinom(1, 1, p) == 1)
if(classi == K+1){
post_theta = a / (a + b)
} else{
post_theta = P[[j]][classi,1:m]
}
new_xi = sapply(1:m, function(x){
return(as.numeric(rbinom(1, 1, p = post_theta[x])))
})
return(new_xi)
})))
}
## BOISE selection based on pel1
step = 1
pel1 = unlist(mclapply(1:dim(x0)[2], function(x){
return(pel1_beta(cl, P, iter, size, A = x, nA = step, nT,a,b,x0, alpha))},
mc.cores = detectCores()))
tmp = order(pel1)[1]
inform = tmp
candidate = order(pel1)
while (step < nA) {
step = step +1
candidate = candidate[-which(candidate == tmp)]
pel = rep(0,length(candidate))
pel = unlist(mclapply(candidate, function(x){
return(pel1_beta(cl, P, iter, size, A = c(inform,x), nA = step,nT,a,b,x0, alpha))},
mc.cores = detectCores()))
print("ah")
tmp = candidate[order(pel)[1]]
inform = c(inform, tmp)
}
return(inform)
}
inform = Boise(cl_sample, iter,size, nA = nA, nT = nT,a,b, x0 = train,alpha)
Boise <- function(cl_sample, iter, size, nA, nT, a, b, x0, alpha){
#source("clust_sum.R")
#source("npel1.R")
if (!require('parallel')) {
stop('The package parallel was not installed')
}
P = clust_sum(cl_sample,x0,iter, a, b)
n = nrow(x0)
m = ncol(x0)
cl = cl_sample
cl$XX = rep(0, iter*size*m)
dim(cl$XX) = c(iter, size, m)
## Sample for x_i* with sample size "size"
for (j in 1:iter) {
K = cl$KK[j]
p = rep(0, K + 1)
p[K + 1] = alpha / (n + alpha)
p[1:K] = P[[j]][,m+1] / (n+alpha)
cl$XX[j, , ] = t(as.matrix(sapply(1:size, function(s){
classi = which(rmultinom(1, 1, p) == 1)
if(classi == K+1){
post_theta = a / (a + b)
} else{
post_theta = P[[j]][classi,1:m]
}
new_xi = sapply(1:m, function(x){
return(as.numeric(rbinom(1, 1, p = post_theta[x])))
})
return(new_xi)
})))
}
## BOISE selection based on pel1
step = 1
pel1 = sapply(1:dim(x0)[2], function(x){
return(pel1_beta(cl, P, iter, size, A = x, nA = step, nT,a,b,x0, alpha))})
tmp = order(pel1)[1]
inform = tmp
candidate = order(pel1)
while (step < nA) {
step = step +1
candidate = candidate[-which(candidate == tmp)]
pel = rep(0,length(candidate))
pel = unlist(mclapply(candidate, function(x){
return(pel1_beta(cl, P, iter, size, A = c(inform,x), nA = step,nT,a,b,x0, alpha))},
mc.cores = detectCores()))
tmp = candidate[order(pel)[1]]
inform = c(inform, tmp)
}
return(inform)
}
nA = 1
inform = Boise(cl_sample, iter,size, nA = nA, nT = nT,a,b, x0 = train,alpha)
View(cl_sample)
View(pel1_beta)
pel1_beta <- function(cl_sample, P, iter, size, A, nA, nT = 10, a, b, x0, alpha = 2){
#source("npel2.R")
### Compute PEL1
XA = matrix(0, iter*size, nA)
for (i in 1:iter) {
XA[(size*i-size+1):(size*i),] = cl_sample$XX[i, ,A]
}
XA = apply(XA,1,function(x){return(paste(x, collapse = ""))})
tab = table(XA)
YA = names(tab)
l = length(tab)
tmp_pel2 = sapply(1:l, function(x){
xA = as.numeric(strsplit(YA[x], "")[[1]])
post_probs = matrix(0, 1, iter)
post_thetas = matrix(0, iter, ncol(x0))
for (k in 1:iter){
postls = pel2_beta(P[[k]], x0, xA, nA, A, nT, a, b, alpha)
post_probs[k] = postls$post_prob
post_thetas[k, ] = postls$post_theta
}
post_probs = post_probs / (sum(post_probs))
Score = post_probs %*% post_thetas
return(sum(sort(1-Score)[1:nT]))
})
pel1 = (tmp_pel2 * tab) / iter
return(sum(pel1)/size)
}
inform = Boise(cl_sample, iter,size, nA = nA, nT = nT,a,b, x0 = train,alpha)
Boise <- function(cl_sample, iter, size, nA, nT, a, b, x0, alpha){
#source("clust_sum.R")
#source("npel1.R")
if (!require('parallel')) {
stop('The package parallel was not installed')
}
P = clust_sum(cl_sample,x0,iter, a, b)
n = nrow(x0)
m = ncol(x0)
cl = cl_sample
cl$XX = rep(0, iter*size*m)
dim(cl$XX) = c(iter, size, m)
## Sample for x_i* with sample size "size"
for (j in 1:iter) {
K = cl$KK[j]
p = rep(0, K + 1)
p[K + 1] = alpha / (n + alpha)
p[1:K] = P[[j]][,m+1] / (n+alpha)
cl$XX[j, , ] = t(as.matrix(sapply(1:size, function(s){
classi = which(rmultinom(1, 1, p) == 1)
if(classi == K+1){
post_theta = a / (a + b)
} else{
post_theta = P[[j]][classi,1:m]
}
new_xi = sapply(1:m, function(x){
return(as.numeric(rbinom(1, 1, p = post_theta[x])))
})
return(new_xi)
})))
}
## BOISE selection based on pel1
step = 1
pel1 = unlist(mclapply(1:dim(x0)[2], function(x){
return(pel1_beta(cl, P, iter, size, A = x, nA = step, nT,a,b,x0, alpha))},
mc.cores = detectCores()))
tmp = order(pel1)[1]
inform = tmp
candidate = order(pel1)
while (step < nA) {
step = step +1
candidate = candidate[-which(candidate == tmp)]
pel = rep(0,length(candidate))
pel = unlist(mclapply(candidate, function(x){
return(pel1_beta(cl, P, iter, size, A = c(inform,x), nA = step,nT,a,b,x0, alpha))},
mc.cores = detectCores()))
tmp = candidate[order(pel)[1]]
inform = c(inform, tmp)
}
return(inform)
}
inform = Boise(cl_sample, iter,size, nA = nA, nT = nT,a,b, x0 = train,alpha)
nA = 2
nT = 36
size = 1000
inform = Boise(cl_sample, iter,size, nA = nA, nT = nT,a,b, x0 = train,alpha)
## Add 1 more informer
inform = Boise_Aug(cl_sample,iter,size,nT,a,b,x0 = train,alpha,
inform, nAdd = 1)
## To maintain consistency, we would keep the initial clustering samples
## and use the same assignments in all the computations.
nef.result = Evaluate(cl_sample,inform, measure = "nef",test,train,
nT,iter,a,b,alpha)
auc.result = Evaluate(cl_sample, inform, measure = "rocauc",test,train,
nT,iter,a,b,alpha)
mcc.result = Evaluate(cl_sample, inform, measure = "mat",test,train,
nT,iter,a,b,alpha)
f1.result = Evaluate(cl_sample, inform, measure = "f",test,train,
nT,iter,a,b,alpha)
rm(list = ls())
load("GDSC1_cleaned.RData")
